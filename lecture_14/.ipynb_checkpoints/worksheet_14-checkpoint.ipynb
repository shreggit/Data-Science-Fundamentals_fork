{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 14\n",
    "\n",
    "Name:  Shreyas Sudarsan\n",
    "UID: U71890555\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Attribute A = Yes | Class = No) = 3/7\n",
    "\n",
    "P(Attribute B = Divorced | Class = Yes) = 1/3\n",
    "\n",
    "P(Attribute C = High | Class = No) = 3/7\n",
    "\n",
    "P(Attribute C = Mid | Class = Yes) = 3/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Yes, Married, Mid) = P(Yes/C=Yes) * P(Married/C=Yes) * P(Mid/C=Yes) vs P(Yes/C=No) * P(Married/C=No) * P(Mid/C=No)\n",
    "\n",
    "P(Yes/C=Yes) * P(Married/C=Yes) * P(Mid/C=Yes) = 0 * 0 * 3/3 = 0\n",
    "\n",
    "P(Yes/C=No) * P(Married/C=No) * P(Mid/C=No) = 3/7 * 4/7 * 1/7 = 12/343\n",
    "\n",
    "ans) **Class No**\n",
    "\n",
    "\n",
    "(No, Divorced, High) = P(No/C=Yes) * P(Divorced/C=Yes) * P(High/C=Yes) vs P(No/C=No) * P(Divorced/C=No) * P(High/C=No)\n",
    "\n",
    "P(No/C=Yes) * P(Divorced/C=Yes) * P(High/C=Yes) =  3/3 * 1/3 * 0/3\n",
    "\n",
    "P(No/C=No) * P(Divorced/C=No) * P(High/C=No) = 4/7 * 1/7 * 3/7 = 12/343\n",
    "\n",
    "ans) **Class No**\n",
    "\n",
    "(No, Single, High) = P(No/C=Yes) * P(Single/C=Yes) * P(High/C=Yes) vs P(No/C=No) * P(Single/C=No) * P(High/C=No)\n",
    "\n",
    "P(No/C=Yes) * P(Single/C=Yes) * P(High/C=Yes) = 3/3 * 2/3 * 0/3 = 0\n",
    "\n",
    "P(No/C=No) * P(Single/C=No) * P(High/C=No) = 4/7 * 2/7 * 3/7 = 24/343\n",
    "\n",
    "ans) **Class No**\n",
    "\n",
    "\n",
    "(No, Divorced, Low) = P(No/C=Yes) * P(Divorced/C=Yes) * P(Low/C=Yes) vs P(No/C=No) * P(Divorced/C=No) * P(Low/C=No)\n",
    "\n",
    "P(No/C=Yes) * P(Divorced/C=Yes) * P(Low/C=Yes) = 3/3 * 1/3 * 0/3 = 0\n",
    " \n",
    "P(No/C=No) * P(Divorced/C=No) * P(Low/C=No) = 4/7 * 1/7 * 3/7 = 12/343"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 2, 'fp': 3, 'tn': 4, 'fn': 1}\n"
     ]
    }
   ],
   "source": [
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "def confusion_matrix(actual, predicted):\n",
    "    cm = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "    for a, p in zip(actual_class, predicted_class):\n",
    "        if a == p == \"Yes\":\n",
    "            cm['tp'] += 1\n",
    "        elif a == p == \"No\":\n",
    "            cm['tn'] += 1\n",
    "        elif a == \"Yes\" and p == \"No\":\n",
    "            cm['fn'] += 1\n",
    "        else:\n",
    "            cm['fp'] += 1\n",
    "    return cm\n",
    "            \n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost = 2 * (-1) + 5 * (1) + 10 * (3) + 0 * (4) = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(actual, predicted, cost_matrix):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    cost = []\n",
    "    for key in cost_matrix:\n",
    "        cost.append(cm[key]*cost_matrix[key])    \n",
    "    cost_sum = sum(cost)\n",
    "    return cost_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement functions for the following:\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f-measure\n",
    "\n",
    "and apply them to the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 2, 'fp': 3, 'tn': 4, 'fn': 1}\n",
      "Accuracy: 0.6\n",
      "Precision: 0.4\n",
      "Recall: 0.6666666666666666\n",
      "F-Measure: 0.5\n"
     ]
    }
   ],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    true_positive = confusion_matrix[\"tp\"]\n",
    "    true_negative = confusion_matrix[\"tn\"]\n",
    "    false_positive = confusion_matrix[\"fp\"]\n",
    "    false_negative = confusion_matrix[\"fn\"]\n",
    "    \n",
    "    total_predictions = true_positive + true_negative + false_positive + false_negative\n",
    "    \n",
    "    if total_predictions == 0:\n",
    "        return 0  # To avoid division by zero\n",
    "    \n",
    "    return (true_positive + true_negative) / total_predictions\n",
    "\n",
    "def precision(confusion_matrix):\n",
    "    true_positive = confusion_matrix[\"tp\"]\n",
    "    false_positive = confusion_matrix[\"fp\"]\n",
    "    \n",
    "    if (true_positive + false_positive) == 0:\n",
    "        return 0  # To avoid division by zero\n",
    "    \n",
    "    return true_positive / (true_positive + false_positive)\n",
    "\n",
    "def recall(confusion_matrix):\n",
    "    true_positive = confusion_matrix[\"tp\"]\n",
    "    false_negative = confusion_matrix[\"fn\"]\n",
    "    \n",
    "    if (true_positive + false_negative) == 0:\n",
    "        return 0  # To avoid division by zero\n",
    "    \n",
    "    return true_positive / (true_positive + false_negative)\n",
    "\n",
    "def f_measure(confusion_matrix, beta=1):\n",
    "    precision_value = precision(confusion_matrix)\n",
    "    recall_value = recall(confusion_matrix)\n",
    "    \n",
    "    if (precision_value + recall_value) == 0:\n",
    "        return 0  # To avoid division by zero\n",
    "    \n",
    "    return (1 + beta**2) * (precision_value * recall_value) / ((beta**2 * precision_value) + recall_value)\n",
    "\n",
    "# Example usage\n",
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "conf_matrix = confusion_matrix(actual_class, predicted_class)\n",
    "print(conf_matrix)\n",
    "\n",
    "acc = accuracy(conf_matrix)\n",
    "prec = precision(conf_matrix)\n",
    "rec = recall(conf_matrix)\n",
    "f1 = f_measure(conf_matrix)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F-Measure:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
